{"name":"Terracuda","tagline":"A high-level API for low-level parallelism in Lua by wcrichto and ppinkert","body":"## Summary\r\nWe will create a CUDA API for Lua aimed at programmers unfamiliar with GPU-level parallelism.\r\n\r\n## Background\r\n[Lua](http://www.lua.org/) is a fast, lightweight, and embeddable scripting language found in places like Wikipedia, World of Warcraft, Photoshop Lightroom, and more. Lua's simple syntax and dynamic typing also make it an ideal language for novice programmers. Traditionally, languages like Lua find themselves abstracted miles above low-level parallel frameworks like [CUDA](http://www.nvidia.com/object/cuda_home_new.html), and consequently GPU parallelism was limited to programmers using a systems language like C++. Frameworks like [Terra](http://terralang.org/), however, work to close that gap, making low-level programming accessible in a high-level interface. However, these interfaces still require a number of calls to C libraries and intimate knowledge of the CUDA library. For example, the following code runs a simple CUDA kernel in Terra:\r\n\r\n    terra foo(result : &float)\r\n        var t = tid()\r\n        result[t] = t\r\n    end\r\n\r\n    local R = terralib.cudacompile({ bar = foo })\r\n\r\n    terra run_cuda_code(N : int)\r\n        var data : &float\r\n        C.cudaMalloc([&&opaque](&data),sizeof(float)*N)\r\n        var launch = terralib.CUDAParams { 1,1,1, N,1,1, 0, nil }\r\n        R.bar(&launch,data)\r\n        var results : &float = [&float](C.malloc(sizeof(float)*N))\r\n        C.cudaMemcpy(results,data,sizeof(float)*N,2)\r\n        return results;\r\n    end\r\n\r\n    results = run_cuda_code(16)\r\n\r\nOther high-level CUDA bindings like [PyCUDA](http://documen.tician.de/pycuda/) and [JCuda](http://www.jcuda.org/samples/samples.html) suffer the same problem.\r\n\r\n## The Challenge\r\nThe problem is challenging foremost on the level of architecture. Designing an API is never easy, and attempting to expose GPU-level parallelism to a language as high-level as Lua requires a great deal of care to be usable while still being useful. Creating such an API requires significant knowledge of the abstraction layers between Lua, C, and CUDA as well as knowledge of the typical use cases for high-level parallelism. \r\n\r\nMy partner and I know neither Terra nor LLVM (which Terra compiles to), so creating these high-level bindings requires a great deal of initial investment. The existing interface between Terra and CUDA is sketchy at best, so we will need to implement significant new functionality into Terra in order for the Circle Renderer to function properly.\r\n\r\n## Resources\r\nFor machines, we'll just be using any computers equipped with NVIDIA GPUs (i.e. Will's laptop and the Gates 5k machines). No other special hardware/software will be needed. We'll be building upon the Terra language and also using [LuaGL](http://luagl.sourceforge.net/) for some of the demos.\r\n\r\n## Goals\r\nThe project has three main areas: writing the API, creating programs using the API, and benchmarking the code against other languages/compilers.\r\n\r\nWe plan to achieve:\r\n\r\n* **Writing the API**\r\n    * Allow arbitrary Lua code to be executed in the GPU over a table.\r\n    * Optimize threads/warp usage to the input data.\r\n    * Abstract the API such that the user needs no C libraries and as little Terra as possible.\r\n* **Creating programs**\r\n    * Make a simple saxpy\r\n    * Write matrix operations like transpose or pseudoinverse/SVD\r\n    * Port the Assignment 2 Circle Renderer over to vanilla Lua (using LuaGL)\r\n* **Benchmarking**\r\n    * For each program, benchmark it against equivalent implementations in: vanilla Lua, Terra without CUDA, and C.\r\n\r\nWe hope to achieve:\r\n\r\n* Achieve better performance than vanilla C.\r\n* Implement shared memory in Terra.\r\n* Implement linking against libraries like [cublas](https://developer.nvidia.com/cublas).\r\n\r\n## Platform\r\nCUDA makes sense as we've already learned it in class, and Lua makes sense as Terra already laid the foundation for abstracting systems-level code.\r\n\r\n## Schedule\r\n\r\n### Original schedule\r\n* __Friday, April 11__: finish map primitives (ie any Lua code and map over a Lua table in CUDA). Write saxpy and corresponding benchmarks.\r\n* __Friday, April 18__: complete Terracuda API. Write matrix code and benchmarks.\r\n* __Friday, April 25__: Port over Circle Renderer and benchmarks. Gather all requisite data and perform preliminary analysis.\r\n* __Friday, May 2__: Optimize/refactor API based on code written and data found. Search for possible performance gains in the abstraction layer. Attempt to implement library linking.\r\n* __Friday, May 9__: create writeup based on finalized API. Add any remaining features, time permitting (.g. shared memory).\r\n\r\n### New schedule\r\n* __Wednesday, April 23__: implement generic kernel/variable and reduce primitives (Will).\r\n* __Sunday, April 27__: finish implementing optimizations in circle renderer (Patrick).\r\n* __Wednesday, April 30__: finish refactors to API. Add shared/constant memory if possible (Will).\r\n* __Sunday, May 3__: finish benchmarking all programs. Gather and graph data. (Patrick).\r\n* __Wednesday, May 7__: complete write-up (Will and Patrick). Time permitting, make more demos.\r\n\r\n## Checkpoint\r\n\r\nThe project is proceeding mostly according to plan. Here's the highlights:\r\n\r\n* Because of some troubles with installation/setup/learning overhead, the API is not as close to completion as it should be. That said, as you can see in the Github repo we have made significant progress in creating a high-level CUDA API. We have multiple flavors of a map primitive (which is the basic underpinning of any CUDA program). Soon we'll have support for managing multiple variables/kernels within a CUDA program instead of a single list. \r\n* We've benchmarked a basic program and seen some cool performance gains. We ran the following code over an array length 100k\r\n\r\n        terra do_work(x : int) : int\r\n           var y : int = 0\r\n           for i = 0, 10000 do\r\n              if i % 3 == 0 or i % 5 == 0 then\r\n                 y = y + 1\r\n              end\r\n           end\r\n           return x + y\r\n        end\r\n    And we found speedups of 7.6x over JIT'd Terra, 14.34x over native C, and within 0.95x of hand-rolled CUDA. And the mapping API is really easy to use, it just looks like:\r\n    \r\n        local kernel = cuda.lua_map(do_work)\r\n        kernel(some_list)\r\n    And `some_list` gets modified in-place. \r\n* After a lot of blood and tears, we managed to port the serial and CUDA circle renderers to Lua (so we are ahead of schedule in that respect!). We still need to implement the optimizations from asst2 (e.g. quadtree data structure on the circles) and change it to use more of our newly minted API, but that should come quickly in the next few weeks. For the competition, we'll show off the circle renderer and any other examples we may come up with before then. We'll also have graphs comparing speed and code size using our API. \r\n* At this point, most of the work is just programming and any further API design as our needs develop. We're not facing any serious issues at this point. ","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}